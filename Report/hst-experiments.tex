\chapter{Experimenten} % (fold)
\label{cha:experimenten}
Dit hoofdstuk bevat een overzicht van de uitgevoerde experimenten. Alle experimenten gebeurden met een aantal ongewijzigde instellingen, die de eerste sectie bespreekt. De tweede sectie beschrijft experimenten die de modellen trainen en evalueren met als doel absoluut betere resultaten te halen dan een referentiemodel. Een tweede type van experimenten bekijkt het effect van wijzigingen in een aantal parameters. De laatste sectie behandelt het effect van ruis op twee gLSTM implementaties.

\section{Algemene instellingen} % (fold)
\label{sec:eigen_implementaties_exp}
Het doel van deze masterproef is om de basisresultaten van de paper en bijbehorende implementatie van Karpathy\cite{Karpathy2015} te verbeteren. Om die reden volgen we nauwgezet dezelfde types van experimenten. Daarom doet VGGNet met 16 lagen dienst als convolutioneel netwerk. Daarnaast vormt de  Flickr30k dataset de basis voor de experimenten met dezelfde test-, train- en validatiedeelverzameling als deze in de paper van Karpathy. Trainen van de netwerken en toegevoegde uitbreidingen gebeurt met behulp van de trainingset. Het afstellen van de parameters van deze modellen gebeurt op basis van scores op de validatieset. De uiteindelijke evaluatie gebeurt op de testset. Op deze manier traint elk model onafhankelijk van de testverzameling en kan een correcte vergelijking gebeuren met de rest van de literatuur.

De verschillende modellen trainen met de volgende standaardinstellingen: leersnelheid 0.0001, type solver \texttt{rmsprop}, decay rate 0.999, epsilon smoothing 1e-8, batch-grootte 100, gradient clipping 5, drop-out in encoder en decoder 0.5.
De gebruikte verborgen laag, afbeeldingscodering en woordcodering hebben steeds een grootte van 256. Hierbij is de afbeeldingscodering en woordcodering de vector verkregen na de vermenigvuldiging van de representatie met een gewichtsmatrix.

Tijdens het trainen van de modellen slaagt het systeem op vaste momenten het huidige netwerk op samen met de perplexity van de validatieset. Karpathy kiest als finaal model voor het netwerk met de beste perplexity. Uit enkele eenvoudige testen blijkt dat de perplexity slechts beperkt overeenkomt met de BLEU-score. Om die reden kiezen dient het netwerk dat de beste BLEU-4 score op de validatieset heeft als finaal model voor elke configuratie.

Beam search is het algoritme dat zorgt voor het genereren van de zinnen. In de algemene experimenten is de beam-grootte steeds $50$.
BLEU-scores (1-4), METEOR-scores en enkele statistieken dienen als evaluatiemetriek. Deze scores zijn berekend met behulp van de vijf referentiezinnen uit Flickr30k.

We vermoeden dat Karpathy gebruik maakt van een Brevity Penalty bij de BLEU-scores. In dit werk en in andere werken in de literatuur gebeurt dit echter niet.

\section{Verbeteringen op startpunt}
Karpathy gebruikte een Brevity Penalty bij de evaluatie van zijn resultaten in de originele paper. In dit werk gebeurt dit niet. Daarnaast is Karpathy's implementatie van het LSTM-netwerk van Vinyals geen exacte kopie. Om die redenen is het niet mogelijk om een correcte vergelijking te maken met de resultaten in beide papers. Daarom is er een noodzaak aan eigen referentiewaarden. Zonder wijzigingen aan te brengen aan de originele code, zorgt een uitvoering met de algemene instellingen voor zowel RNN als LSTM voor deze referentiewaarden. Die waarden vormen dan de richtpunten, waarvoor een verbetering wordt gezocht.
Daarna volgen experimenten met de zelf geschreven uitbreidingen. RNN bevat een uitbreiding met LDA. LSTM bevat uitbreidingen met als gids LDA en CCA.
Na het trainen en evalueren van deze modellen, wordt ook het effect van Gaussiaanse normalisatie, Min-Hinge normalisatie en IDF-normalisatie getest.
Een vergelijking met de referentiewaarden bepaalt of een uitbreiding al dan niet een verbetering inhoudt.

\section{Wijzigen van parameters}
Naast het toevoegen van uitbreidingen aan het startpunt, loont het de moeite om te kijken wat het effect is van individuele parameters op deze modellen. Bij LDA vormt het aantal onderwerpen de belangrijkste te controleren parameter. Bij CCA wordt de grootte van de gebruikte vector beschouwd. Ook het al dan niet invoeren van de afbeelding op elke tijdstap van het RNN is een te wijzigen parameter. Als laatste bekijken we het effect van verschillende gewichten voor de gecombineerde IDF-Gauss normalisatie.

\section{Ruisgevoeligheid van CCA en LDA} % (fold)
\label{sec:ruisgevoeligheid_van_cca_en_lda_exp}
gLSTMs maken het mogelijk om extra semantische informatie aan het taalmodel toe te voegen. Deze informatie kan uit verschillende bronnen komen. In deze masterproef bekeken we CCA en LDA. Naast de absolute scores die de twee modellen halen, is het ook interessant om te kijken naar welk van de modellen het meest robuust is tegen ruis in de referentiezinnen.

Om deze eigenschap te evalueren cre\"eren we een nieuwe dataset waarbij de referentiezinnen van de trainingsset kleine wijzigingen bevatten.
Concreet wordt elk woord vervangen door een willekeurig woord in het vocabularium met een kans van 10\%. Hierna traint het netwerk op dezelfde manier als hierboven beschreven. Na deze training en generatie van resultaten op de testverzameling is een vergelijking mogelijk. Dit doont dan aan welke gids het meeste last heeft van deze extra ruis in de dataset.

% section besluit (end)

