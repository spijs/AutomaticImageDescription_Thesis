\chapter{Experimenten} % (fold)
\label{cha:experimenten}
Dit hoofdstuk bevat een overzicht van de experimenten die zijn uitgevoerd. Enerzijds zijn er experimenten die de modellen trainen en evalueren om absoluut betere resultaten te halen dan het basismodel. Anderzijds bekijken we het effect van ruis op twee gLSTM implementaties.

\section{Eigen implementaties} % (fold)
\label{sec:eigen_implementaties}
Het doel van deze masterproef is om de basisresultaten van de paper en bijbehorende implementatie van Karpathy\cite{Karpathy2015} te verbeteren. Om die reden volgen we nauwgezet dezelfde types van experimenten. Daarom doet hetzelfde VGGNet met 16 lagen dienst als convolutioneel netwerk. Daarnaast voeren we alle experimenten uit op de Flickr30k dataset en gebruiken we dezelfde test-, train- en validatiedeelverzameling als deze in de paper. We trainen het netwerk en de toegevoegde uitbreidingen met behulp van de trainingset. Het afstellen van de parameters van deze modellen gebeurt op basis van scores op de validatieset. De uiteindelijke evaluatie gebeurt op de testset. Op deze manier is geen enkel model getraind op de test set en kan een correcte vergelijking gebeuren met de rest van de literatuur.

We vermoeden echter dat Karpathy gebruik maakt van een brevity penalty \todo{quotes?} bij de Bleu scores. In dit werk en in andere werken in de literatuur gebeurt dit echter niet. Om die reden doen we eerst experimenten met de standaard instellingen van de code van Karpathy voor zowel het RNN als LSTM model. De resultaten hiervan vormen dan de referentiewaarden die moeten worden verbeterd. 

De verschillende modellen zijn getraind met de volgende instellingen: leersnelheid 0.0001, type solver rmsprop, decay rate 0.999, epsilon smoothing 1e-8, batch-size 100, gradient clipping 5, dropout in encoder en decoder 0.5. \todo{Dit fixen :D}

Beam search is het algoritme dat zorgt voor het genereren van de zinnen. In onze experimenten is de beam-grootte steeds 50.
BLEU-scores (1-4), METEOR-scores en enkele statistieken dienen als evaluatiemetriek en zijn berekend met behulp van steeds vijf referentiezinnen.

Naast de referentiewaarden voeren we ook experimenten uit op onze eigen geschreven uitbreidingen.
Deze bevatten RNN uitgebreid met LDA, gLSTM met CCA voor verschillende groottes van CCA-vector, gLSTM met LDA voor verschillende groottes van topics. Daarnaast bekijken we ook het effect van Gaussiaanse normalisatie en Min-Hinge normalisatie op elk van deze modellen.

\section{Ruisgevoeligheid van CCA en LDA} % (fold)
\label{sec:ruisgevoeligheid_van_cca_en_lda}
gLSTMS maken het mogelijk om extra semantische informatie aan het taalmodel te geven. Deze informatie kan uit verschillende bronnen komen. In deze masterproef bekeken we CCA en LDA. Naast de absolute scores die de twee modellen halen is het ook interessant om te kijken naar welk van de modellen het meest robuust is tegen perturbaties in de referentiezinnen.
Om deze eigenschap te evalueren cre\"eren we een nieuwe dataset waarbij de referentiezinnen van de trainingsset perturbaties bevatten.
Concreet wordt elk woord vervangen door een willekeurig woord in het vocabularium met een kans van 10\%. Hierna traint het netwerk op dezelfde manier als hierboven beschreven. Na de evaluatie van de resultaten is het mogelijk om te bekijken welk van de modellen relatief het meeste last heeft van deze extra ruis in de dataset.

% section besluit (end)

