\documentclass[master=cws,masteroption=ai]{kulemt}
\setup{title={Automatisch beschrijven van afbeeldingen met natuurlijke taal},
  author={Thijs Dieltjens \and Wout Vekemans},
  promotor={Prof.\,dr.\ Marie-Francine Moens},
  assessor={},
  acyear={2015 -- 2016},
  assistant={Ir.\ S. Zoghbi}}
% De volgende \setup mag verwijderd worden als geen fiche gewenst is.
\setup{filingcard,
  translatedtitle={Image Description Using Natural Language},
  udc=681.3,
  shortabstract={Het automatisch beschrijven van afbeeldingen is een complexe taak die elementen uit computervisie en natuurlijke taalverwerking samenbrengt. Het doel van een beschrijvingssysteem bestaat erin om vloeiende, grammaticaal correcte zinnen te genereren die een afbeelding maximaal beschrijven. Deze thesis breidt hiervoor twee bestaande systemen op basis van neurale netwerken uit. In deze systemen vormt een convolutioneel neuraal netwerk de afbeeldingen om tot een vectorvoorstelling. Een recurrent neuraal netwerk dient als taalmodel dat deze afbeeldingsrepresentatie als invoer krijgt. Deze netwerken trainen en testen op vooraf samengestelde verzamelingen met afbeeldingen en bijbehorende beschrijvingen. De bestaande systemen maken dikwijls fouten in de beschrijvingen of genereren eerder vage zinnen. 
  Daarom voegt een eerste uitbreiding van deze masterproef extra semantische informatie toe aan het taalmodel. Dit werk bestudeert twee bronnen van semantische informatie. Als eerste bron leert een neuraal netwerk uit afbeeldingen een onderwerpverdeling te extraheren. Deze verdeling kan de generatie van beschrijvingen in de juiste richting sturen. Een projectie in de multimodale ruimte tussen afbeeldingen en zinnen vormt de tweede bron van informatie.
  Beide semantische toevoegingen zorgen voor verbeteringen tegenover de beschouwde bestaande systemen.
  Experimenten naar de ruisgevoeligheid van beide informatiebronnen tonen aan dat de projectie in de multimodale ruimte hiertegen beter bestand is.
  De tweede uitbreiding is een normalisatiefunctie die focust op minder gebruikte woorden in de trainingsverzameling met als doel creatievere en minder vage zinnen te genereren. Experimenten wijzen uit dat deze methode zorgt voor een grotere woordenschat en meer unieke en menselijkere beschrijvingen. Helaas is deze tweede normalisatie niet altijd in staat om de afbeelding op een grammaticaal en inhoudelijk correcte wijze te beschrijven.
  De derde uitbreiding op het initieel systeem is een normalisatiefunctie die tijdens het genereren van zinnen voor langere en meer kwalitatieve beschrijvingen zorgt. Het definieert hiervoor een functie die als doel heeft de zinslengteverdeling van de trainingsverzameling na te bootsen.}}
% Verwijder de "%" op de volgende lijn als je de kaft wil afdrukken
% \setup{coverpageonly}
% Verwijder de "%" op de volgende lijn als je enkel de eerste pagina's wil
% afdrukken en de rest bv. via Word aanmaken.
%\setup{frontpagesonly}

% Kies de fonts voor de gewone tekst, bv. Latin Modern
\setup{font=lm}

% Hier kun je dan nog andere pakketten laden of eigen definities voorzien
\usepackage{multirow}
\usepackage{url}
\usepackage{csquotes}
\usepackage{todonotes}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{bbm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{epsfig}
\usepackage[]{epstopdf}
\usepackage[export]{adjustbox}
\usepackage{subcaption}
\usepackage{capt-of}
\usetikzlibrary{shapes.geometric, arrows}


\DeclareGraphicsExtensions{.pdf,.png,.jpg,.PNG}
% Tenslotte wordt hyperref gebruikt voor pdf bestanden.
% Dit mag verwijderd worden voor de af te drukken versie.
\usepackage[pdfusetitle,plainpages=false]{hyperref}

\newcommand{\myvector}[1]{$\mathbf{#1}$}

%%%%%%%
% Om wat tekst te genereren wordt hier het lipsum pakket gebruikt.
% Bij een echte masterproef heb je dit natuurlijk nooit nodig!
\IfFileExists{lipsum.sty}%
 {\usepackage{lipsum}\setlipsumdefault{11-13}}%
 {\newcommand{\lipsum}[1][11-13]{\par Hier komt wat tekst: lipsum ##1.\par}}
%%%%%%%

%\includeonly{hfdst-n}
\begin{document}

\begin{preface}
In dit voorwoord willen we graag iedereen bedanken die deze masterproef mee mogelijk heeft gemaakt.

Ten eerste is er professor Moens, die ons het zeer interessante onderwerp heeft aangereikt. Daarnaast zorgde ze voor de nodige kritische vragen en bedenkingen. We willen haar ook bedanken voor het nalezen van de tekst.

Ook willen we onze begeleidster Susana Zoghbi bedanken, om ons bij te staan in het zoeken naar relevante literatuur en mogelijke oplossingen. Ze stond ook altijd klaar met de nodige feedback op onze resultaten en werkwijze en geloofde steeds in de goede afloop van ons onderzoek.

Onze dank gaat ook uit naar Annick en Annemie, voor het nalezen van de uiteindelijke tekst en hem in de mate van het mogelijke te ontdoen van typ-, spel- en andere fouten. 

Tenslotte willen we graag onze kotgenoten, Anjulie, Marieke, Hubble en Cyndaquil bedanken voor de mentale steun en de nodige ontspanning tijdens het schrijven.

Moesten we iemand vergeten zijn in dit dankwoord, alvast onze excuses.

\end{preface}

\tableofcontents*

\begin{abstract}
  Het automatisch beschrijven van afbeeldingen is een complex probleem. Het combineert componenten uit de vakgebieden van computervisie en natuurlijke taalverwerking. Voor een machine is het niet eenvoudig om deze twee domeinen te verbinden tot een kwalitatief afbeeldingsbeschrijvend systeem. De literatuur biedt een aantal mogelijke oplossingen die op basis van een dataset met afbeeldingen leren om automatisch correcte beschrijvingen te genereren. Een veel voorkomend probleem met deze systemen is dat een groot deel van de gegenereerde zinnen niet aansluit bij wat mensen als kwalitatief ervaren. De gebruikte woorden zijn te algemeen en tonen weinig verband met de foto. Vaak zijn de gegenereerde zinnen ook korter dan de beschrijvingen die een mens zou geven.
 
 Deze masterproef biedt een aantal oplossingen voor deze problemen. Dit werk vertrekt vanaf een bestaande implementatie van twee systemen. Deze systemen gebruiken een eerste neuraal netwerk om afbeeldingen om te zetten in vectorvoorstellingen. Vervolgens dient deze voorstelling als invoer in een tweede neuraal netwerk dat als taalmodel dient. Uit dit taalmodel bepaalt een algoritme dan de meest waarschijnlijke beschrijving. Deze systemen trainen en testen met vooraf samengestelde verzamelingen van afbeeldingen en bijbehorende beschrijvingen.
 
 Het toevoegen van semantische informatie uit de afbeelding aan de twee bestaande systemen maakt het mogelijk om zinnen te genereren die beter overeenkomen met de afbeelding en die een bredere woordenschat gebruiken. Het onderzoek focust op twee specifieke vormen van informatie. Ten eerste is er informatie die verband houdt met onderwerpen die aanwezig zijn in de afbeelding. Uit de afbeeldingen en zinnen uit de trainingsset leert het systeem een verband tussen afbeelding en onderwerp. Een projectie bepaalt dan de onderwerpen die in elke ongeziene afbeelding aanwezig zijn. Op die manier gebruikt het beschrijvingssysteem woorden die beter aansluiten bij de onderwerpen aanwezig in de afbeelding. Een tweede manier om informatie toe te voegen is het gebruik van een multimodale ruimte tussen afbeelding en tekst. Een CCA-projectie maakt het mogelijk om een ruimte te leren waarin overeenkomstige afbeeldingen en zinnen maximaal correleren. Door nieuwe afbeeldingen in deze ruimte te projecteren verkrijgt het systeem informatie over welke zinnen dicht in de buurt van de afbeelding liggen, om zo de generatie in de juiste richting te sturen. De experimenten maken duidelijk dat beide technieken zorgen voor verbeteringen.
 
 Een tweede aangebrachte verbetering focust op de lengte van de zinnen. Door een normalisatie toe te voegen aan de laatste stap van het generatieproces is het mogelijk om bepaalde zinnen te verkiezen op basis van hun lengte. Op die manier is er voorkeur voor zinnen die qua lengte beter overeen komen met de trainingszinnen. Uit de experimenten blijkt dat het toevoegen van normalisatie leidt tot een meer uniforme verdeling van de zinslengtes die beter aansluit bij die van de trainingsset. Bovendien stijgt hierdoor de kwaliteit van de beschrijvingen.
 
 Een tweede normalisatiemethode focust op de creativiteit van de zinnen. Door te mikken op minder vaak gebruikte woorden in de trainingsset slaagt het systeem er in om een grotere woordenschat te leren en meer unieke beschrijvingen te genereren. Helaas gaat deze creativiteit dikwijls gepaard met foutieve zinsconstructies en beschrijvingen die afwijken van de inhoud van de afbeelding.
 
 Tenslotte biedt deze masterproef een vergelijking van de twee manieren om semantische informatie toe te voegen. Een perturbatie van de dataset door het vervangen van een aantal woorden leidt tot een vergelijking op gebied van ruisgevoeligheid. Experimenten wijzen uit de de multimodale projectie beter bestand is tegen dit type van ruis.
 
 De uiteindelijke resultaten van de beste modellen in deze masterproef presteren zeker niet ondermaats in de vergelijking met de meest recente literatuur. Bovendien was het perfect afstellen van de gebruikte modellen niet mogelijk door de hoge trainingstijd die de neurale netwerken vragen. Werken in de literatuur die aandachtsmodellen toevoegen aan hun systeem presteren wel steeds beter. Dit gaat weliswaar ten koste van extra complexiteit, maar is zeker interessant voor toekomstig onderzoek.
 \end{abstract}

% Een lijst van figuren en tabellen is optioneel
%\listoffigures
%\listoftables
% Bij een beperkt aantal figuren en tabellen gebruik je liever het volgende:
\listoffiguresandtables
% De lijst van symbolen is eveneens optioneel.
% Deze lijst moet wel manueel aangemaakt worden, bv. als volgt:
\chapter{Lijst van afkortingen en symbolen}
\section*{Afkortingen}
\begin{flushleft}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabularx}{\textwidth}{@{}p{25mm}X@{}}
  	B$n$ & Bleu $n$\\
  	BP & Brevity Penalty\\
  	CCA & Canonical Correlation Analysis \\
  	CNN & Convolutioneel Neuraal Netwerk \\
  	CV & Computervisie (Computer Vision) \\
  	FSMN & Fast-forward Sequential Memory Neural network\\
  	gLSTM & Guided Long Short Term Memory \\
    LDA  & Latent Dirichlet Allocation \\
    LSTM & Long Short Term Memory \\
    (MS) COCO & Microsoft Common Objects in COntext dataset\\
    NIC & Neural Image Caption Generator~\cite{Google}\\
    NLP & Natural Language Processing\\
    NP & Noun Phrase (naamwoordgroep)\\
    POS & Part of Speech (woordsoort)\\
    PP & Propositional Phrase (voorzetselgroep)\\
    RCNN & Region Convolutional Neural Network \\
    ReLu & Rectified Linear Unit\\
    RFF & Random Fourier Feature \\
    RGB & Rood-Groen-Blauw\\
    RNN & Recurrent Neuraal Netwerk \\
    SWO & Singulierewaardenontbinding \\
    tf-idf & Termfrequentie en inverse document frequentie \\
	VDR & Visual Dependency Representation (Visuele Afhankelijkheid Representatie)\\
	VP & Verb Phrase (werkwoordgroep)\\

  \end{tabularx}
\end{flushleft}


\section*{Symbolen}
\begin{flushleft}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabularx}{\textwidth}{@{}p{25mm}X@{}}
  	$a_t$ & Gradi\"ent op tijdstip $t$\\
  	$a_{wt}$ & Bewegend gemiddelde van gewichtsupdates \\ 
  	$A$ & CCA-projectie\\
  	$b_i$ & Biasvector neuraal netwerk \\
  	$B$ & CCA-projectie\\
  	$BP$& Brevity Penalty voor Bleu-scores \\
  	$CNN_{\theta_c}$ & Output voorlaatste laag van CNN \\
  	$c$& Totaal aantal woorden van gegenereerde zinnen \\
  	$ch$ & Aantal chunks (Meteor) \\
  	$c'_t$ &Waarde van LSTM-geheugencel op tijdstip $t$ \\
  	$Count$ & Aantal voorkomens van een gegeven woordsequentie \\
  	$Count_{clip}$ & Minimum van aantal voorkomens in referentiezinnen en te evalueren zin \\
  	$d_j$ & $j$de document LDA \\
  	$E$ & Foutenfunctie\\
  	$f$ & Transferfunctie van neuraal netwerk\\
  	$g$ & Gidsvector bij gLSTM \\
  	$h$ & Verborgen laag neuraal netwerk\\
	$H$ & Entropie\\
	$i'_t$ & Inputvector LSTM \\
	$idf$ &Inverse documentfrequentie \\
	$I$& Afbeeldingsvector \\
	$j$ & Vector voor Random Fourier Feature \\
	$l$ & Aantal woorden in een zin \\
	$L$ & LDA-onderwerpverdeling \\
	$LSTM(x)$& Output LSTM-netwerk voor input $x$ \\
	$m$ & Gemiddeld aantal gematchte woorden \\
	$\textbf{o}$ & Outputvector\\
	$p(x)$ & Kans op gebeurtenis x\\
	$P(x|y) $& Voorwaardelijke kans\\
	$PP$ & Perplexiteit \\
	$q$ & Som van de lengtes van beste matches (Bleu)\\
	$r$& Recall \\
	$R$ & Matrix voor Random Fourier Feature \\
	$s$ & Zin \\
	$sd$ & Standaardafwijking zinlengtes\\
	$sm$ & Softmaxfunctie\\
	$tf$& Termfrequentie \\
	$u'_t$ & Output van LSTM-cel \\


	  \end{tabularx}
	\end{flushleft}
	
\begin{flushleft}
	\renewcommand{\arraystretch}{1.1}
	\begin{tabularx}{\textwidth}{@{}p{25mm}X@{}}
	$U$ &Projectiematrix CCA \\
	$v'_t$& Vergeetvector LSTM \\
	$V$ &Vocabularium LDA \\
	$w$ & Gewichtsvector\\
	$W$ & Gewichtsmatrix \\
	$x_i$ & Inputvector\\
	$x_i$ &$i$de woord\\
	$y$ & Outputvector neuraal netwerk\\
	$z_{k}$ & $k$de onderwerp van LDA \\
	$\alpha$ & Dirichlet prior\\
	$\beta$ & Dirichlet prior \\
	$\gamma$ & Parameter Meteor\\
	$\delta_{ik}$ & Kroneckerdelta functie\\
	$\epsilon$ & Afvlakkingsparameter\\
	$\eta$ & Leersnelheid neuraal netwerk\\
    $\theta$ & Kansverdeling onderwerpen per document (LDA)\\
	$\kappa$ & Parameter Meteor \\
	$\lambda$ & Parameter Meteor \\
	$\mu$ & Gemiddelde zinlengte\\
	$\rho$ & Afvlakkingsparameter\\
	$\sigma$ & Sigmo\"idefunctie \\
	$\phi$ & Kansverdeling woorden per onderwerp (LDA)\\
	$\psi$ & Lineaire functie Stacked CCA \\
	$\Omega$ & Normalisatiefactor bij beam search \\
		
	\end{tabularx}
\end{flushleft}

% Nu begint de eigenlijke tekst
\mainmatter

\include{hst-inleiding}
\include{hst-probleem}
\include{hst-related}
\include{hst-theorie}
\include{hst-methodology}
\include{hst-evaluation}
\include{hst-experiments}
\include{hst-resultaten}
% ... en zo verder tot
\include{besluit}

% Indien er bijlagen zijn:
\appendixpage*          % indien gewenst
\appendix
\include{app-LDA}
\include{app-LDAprediction}
\include{appResults}

\backmatter
% Na de bijlagen plaatst men nog de bibliografie.
% Je kan de  standaard "abbrv" bibliografiestijl vervangen door een andere.
\bibliographystyle{abbrv}
\bibliography{referenties,extra_references}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
