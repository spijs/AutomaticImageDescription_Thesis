\documentclass[master=cws,masteroption=ai]{kulemt}
\setup{title={Automatisch beschrijven van afbeeldingen met natuurlijke taal},
  author={Thijs Dieltjens \and Wout Vekemans},
  promotor={Prof.\,dr.\, Marie-Francine Moens},
  assessor={},
  acyear={2015 -- 2016},
  assistant={Ir.\ S. Zoghbi}}
% De volgende \setup mag verwijderd worden als geen fiche gewenst is.
\setup{filingcard,
  translatedtitle={Image description using natural language},
  udc=681.3,
  shortabstract={Hier komt een heel bondig abstract van hooguit 500
    woorden. \LaTeX\ commando's mogen hier gebruikt worden. Blanco lijnen
    (of het commando \texttt{\string\pa r}) zijn wel niet toegelaten!
    \endgraf \lipsum[2]}}
% Verwijder de "%" op de volgende lijn als je de kaft wil afdrukken
% \setup{coverpageonly}
% Verwijder de "%" op de volgende lijn als je enkel de eerste pagina's wil
% afdrukken en de rest bv. via Word aanmaken.
%\setup{frontpagesonly}

% Kies de fonts voor de gewone tekst, bv. Latin Modern
\setup{font=lm}

% Hier kun je dan nog andere pakketten laden of eigen definities voorzien
\usepackage{multirow}
\usepackage{url}
\usepackage{csquotes}
\usepackage{todonotes}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{bbm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{epsfig}
\usepackage[]{epstopdf}
\usepackage[export]{adjustbox}
\usepackage{subcaption}
\usepackage{capt-of}
\usetikzlibrary{shapes.geometric, arrows}


\DeclareGraphicsExtensions{.pdf,.png,.jpg,.PNG}
% Tenslotte wordt hyperref gebruikt voor pdf bestanden.
% Dit mag verwijderd worden voor de af te drukken versie.
\usepackage[pdfusetitle,plainpages=false]{hyperref}

\newcommand{\myvector}[1]{$\mathbf{#1}$}

%%%%%%%
% Om wat tekst te genereren wordt hier het lipsum pakket gebruikt.
% Bij een echte masterproef heb je dit natuurlijk nooit nodig!
\IfFileExists{lipsum.sty}%
 {\usepackage{lipsum}\setlipsumdefault{11-13}}%
 {\newcommand{\lipsum}[1][11-13]{\par Hier komt wat tekst: lipsum ##1.\par}}
%%%%%%%

%\includeonly{hfdst-n}
\begin{document}

\begin{preface}
In dit voorwoord willen we graag iedereen bedanken die deze masterproef mee mogelijk heeft gemaakt.

Ten eerste is er professor Moens, die ons het zeer interessante onderwerp heeft aangereikt. Daarnaast zorgde ze steeds voor de nodige kritische vragen en bedenkingen. We willen haar ook bedanken voor het nalezen van de tekst.

Ook willen we onze begeleidster Susana Zoghbi bedanken, om ons bij te staan in het zoeken naar relevante literatuur en mogelijke oplossingen. Ze stond ook steeds klaar met de nodige feedback op onze resultaten en werkwijze en geloofde steeds in de goede afloop van ons onderzoek.

Onze dank gaat ook uit naar Annick en Annemie, voor het nalezen van de uiteindelijke tekst en hem in de mate van het mogelijke te ontdoen van typ-, spel- en andere fouten. 

Tenslotte willen we graag onze kotgenoten, Anjulie, Marieke, Hubble en Cyndaquil bedanken voor de mentale steun en de nodige ontspanning tijdens het schrijven.

Moesten we iemand vergeten zijn in dit dankwoord, alvast onze excuses.

\end{preface}

\tableofcontents*

\begin{abstract}
  Het automatisch beschrijven van afbeeldingen is een complex probleem. Het combineert componenten uit de vakgebieden van computervisie en natuurlijke taalverwerking. Voor een machine is het niet eenvoudig om deze twee domeinen te verbinden tot een kwalitatief afbeeldingsbeschrijvend systeem. De literatuur biedt een aantal mogelijke oplossingen die op basis van een dataset met afbeeldingen leren om automatisch correcte beschrijvingen te genereren. Een veel voorkomend probleem met deze systemen is dat een groot deel van de gegenereerde zinnen niet aansluit bij wat mensen als kwalitatief ervaren. De gebruikte woorden zijn te algemeen en tonen weinig verband met de foto. Vaak zijn de gegenereerde zinnen ook korter dan de beschrijvingen die een mens zou geven.
 
 Deze masterproef biedt een aantal oplossingen voor dit probleem. Het toevoegen van semantische informatie uit de afbeelding aan twee bestaande systemen op basis van neurale netwerken maakt het mogelijk om zinnen te genereren die beter overeenkomen met de afbeelding en die een bredere woordenschat gebruiken. Het onderzoek focust op twee specifieke vormen van informatie. Ten eerste is er informatie die verband houdt met onderwerpen die aanwezig zijn in de afbeelding. Uit de afbeeldingen en zinnen uit de trainingsset leert het systeem een verband tussen afbeelding en onderwerp. Een projectie bepaalt dan de onderwerpen die in elke ongeziene afbeelding aanwezig zijn. Op die manier gebruikt het beschrijvingssysteem woorden die beter aansluiten bij de onderwerpen aanwezig in de afbeelding aanwezig zijn. Een tweede manier om informatie toe te voegen is het gebruik van een multimodale ruimte tussen afbeelding en tekst. Een CCA-projectie maakt het mogelijk om een ruimte te leren waarin overeenkomstige afbeeldingen en zinnen maximaal correleren. Door nieuwe afbeeldingen in deze ruimte te projecteren verkrijgt het systeem informatie over welke zinnen dicht in de buurt van de afbeelding liggen, om zo de generatie in de juiste richting te sturen. De experimenten maken duidelijk dat beide technieken zorgen voor verbeteringen.
 
 Een tweede aangebrachte verbetering focust op de lengte van de zinnen. Door een normalisatie toe te voegen aan de laatste stap van het generatieproces is het mogelijk om bepaalde zinnen te verkiezen op basis van hun lengte. Op die manier is er voorkeur voor zinnen die qua lengte beter overeen komen met de trainingszinnen. Uit de experimenten blijkt dat het toevoegen van normalisatie leidt tot een meer uniforme verdeling van de zinslengtes die beter aansluit bij die van de trainingsset. Bovendien stijgt hierdoor de kwaliteit van de zinnen.
 
 Een tweede normalisatiemethode focust op de creativiteit van de zinnen. Door te mikken op minder vaak gebruikte woorden in de trainingsset slaagt het systeem er in om een grotere woordenschat te leren en meer unieke beschrijvingen te genereren. Helaas gaat deze creativiteit dikwijls gepaard met foutieve zinsconstructies en beschrijvingen.
 
 Tenslotte biedt deze masterproef een vergelijking van de twee manieren om semantische informatie toe te voegen. Perturbatie van de dataset door het vervangen van een aantal woorden leidt tot een vergelijking op gebied van ruisgevoeligheid. Experimenten wijzen uit de de multimodale projectie beter bestand is tegen ruis.
 \end{abstract}

% Een lijst van figuren en tabellen is optioneel
%\listoffigures
%\listoftables
% Bij een beperkt aantal figuren en tabellen gebruik je liever het volgende:
\listoffiguresandtables
% De lijst van symbolen is eveneens optioneel.
% Deze lijst moet wel manueel aangemaakt worden, bv. als volgt:
\chapter{Lijst van afkortingen en symbolen}
\section*{Afkortingen}
\begin{flushleft}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabularx}{\textwidth}{@{}p{25mm}X@{}}
  	B$n$ & Bleu $n$\\
  	BP & Brevity Penalty\\
  	CCA & Canonical Correlation Analysis \\
  	CNN & Convolutioneel Neuraal Netwerk \\
  	CV & Computer Vision \\
  	FSMN & Fast-forward Sequential Memory Neural network\\
  	gLSTM & Guided Long Short Term Memory \\
    LDA  & Latent Dirichlet Allocation \\
    LSTM & Long Short Term Memory \\
    (MS) COCO & Microsoft Common Objects in COntext dataset\\
    NLP & Natural Language Processing\\
    NP & Noun Phrase (naamwoordgroep)\\
    POS & Part of Speech (woordsoort)\\
    PP & Propositional Phrase (voorzetselgroep)\\
    RCNN & Region Convolutional Neural Network \\
    ReLu & Rectified Linear Unit\\
    RFF & Random Fourier Feature \\
    RGB & Rood-Groen-Blauw\\
    RNN & Recurrent Neuraal Netwerk \\
    SWO & Singulierewaardenontbinding \\
    tf-idf & Termfrequentie en inverse document frequentie \\
	VDR & Visual Dependency Representation (Visuele Afhankelijkheid Representatie)\\
	VP & Verb Phrase (werkwoordgroep)\\

  \end{tabularx}
\end{flushleft}


\section*{Symbolen}
\begin{flushleft}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabularx}{\textwidth}{@{}p{25mm}X@{}}
  	$a_t$ & Gradi\"ent op tijdstip $t$\\
  	$a_{wt}$ & Bewegend gemiddelde van gewichtsupdates \\ 
  	$A$ & CCA-projectie\\
  	$b_i$ & Biasvector neuraal netwerk \\
  	$B$ & CCA-projectie\\
  	$BP$& Brevity Penalty voor Bleu-scores \\
  	$CNN_{\theta_c}$ & Output voorlaatste laag van CNN \\
  	$c$& Totaal aantal woorden van gegenereerde zinnen \\
  	$ch$ & Aantal chunks (Meteor) \\
  	$c'_t$ &Waarde van LSTM-geheugencel op tijdstip $t$ \\
  	$Count$ & Aantal voorkomens van een gegeven woordsequentie \\
  	$Count_{clip}$ & Minimum van aantal voorkomens in referentiezinnen en te evalueren zin \\
  	$d_j$ & $j$de document LDA \\
  	$E$ & Foutenfunctie\\
  	$f$ & Transferfunctie van neuraal netwerk\\
  	$g$ & Gidsvector bij gLSTM \\
  	$h$ & Verborgen laag neuraal netwerk\\
	$H$ & Entropie\\
	$i'_t$ & Inputvector LSTM \\
	$idf$ &Inverse documentfrequentie \\
	$I$& Afbeeldingsvector \\
	$j$ & Vector voor Random Fourier Feature \\
	$l$ & Aantal woorden in een zin \\
	$L$ & LDA-onderwerpverdeling \\
	$LSTM(x)$& Output LSTM-netwerk voor input $x$ \\
	$m$ & Gemiddeld aantal gematchte woorden \\
	$\textbf{o}$ & Outputvector\\
	$p(x)$ & Kans op gebeurtenis x\\
	$P(x|y) $& Voorwaardelijke kans\\
	$PP$ & Perplexiteit \\
	$q$ & Som van de lengtes van beste matches (Bleu)\\
	$r$& Recall \\
	$R$ & Matrix voor Random Fourier Feature \\
	$s$ & Zin \\
	$sd$ & Standaardafwijking zinlengtes\\
	$sm$ & Softmaxfunctie\\
	$tf$& Termfrequentie \\
	$u'_t$ & Output van LSTM-cel \\


	  \end{tabularx}
	\end{flushleft}
	
\begin{flushleft}
	\renewcommand{\arraystretch}{1.1}
	\begin{tabularx}{\textwidth}{@{}p{25mm}X@{}}
	$U$ &Projectiematrix CCA \\
	$v'_t$& Vergeetvector LSTM \\
	$V$ &Vocabularium LDA \\
	$w$ & Gewichtsvector\\
	$W$ & Gewichtsmatrix \\
	$x_i$ & Inputvector\\
	$x_i$ &$i$de woord\\
	$y$ & Outputvector neuraal netwerk\\
	$z_{k}$ & $k$de onderwerp van LDA \\
	$\alpha$ & Dirichlet prior\\
	$\beta$ & Dirichlet prior \\
	$\gamma$ & Parameter Meteor\\
	$\delta_{ik}$ & Kroneckerdelta functie\\
	$\epsilon$ & Afvlakkingsparameter\\
	$\eta$ & Leersnelheid neuraal netwerk\\
    $\theta$ & Kansverdeling onderwerpen per document (LDA)\\
	$\kappa$ & Parameter Meteor \\
	$\lambda$ & Parameter Meteor \\
	$\mu$ & Gemiddelde zinlengte\\
	$\rho$ & Afvlakkingsparameter\\
	$\sigma$ & Sigmo\"idefunctie \\
	$\phi$ & Kansverdeling woorden per onderwerp (LDA)\\
	$\psi$ & Lineaire functie Stacked CCA \\
	$\Omega$ & Normalisatiefactor bij beam search \\
		
	\end{tabularx}
\end{flushleft}

% Nu begint de eigenlijke tekst
\mainmatter

\include{hst-inleiding}
\include{hst-probleem}
\include{hst-related}
\include{hst-theorie}
\include{hst-methodology}
\include{hst-evaluation}
\include{hst-experiments}
\include{hst-resultaten}
% ... en zo verder tot
\include{besluit}

% Indien er bijlagen zijn:
\appendixpage*          % indien gewenst
\appendix
\include{app-LDA}
\include{app-LDAprediction}
\include{appResults}

\backmatter
% Na de bijlagen plaatst men nog de bibliografie.
% Je kan de  standaard "abbrv" bibliografiestijl vervangen door een andere.
\bibliographystyle{abbrv}
\bibliography{referenties,extra_references}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
